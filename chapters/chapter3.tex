%!TEX program=luatex

\newpage
\section{Introduction}
La réalisation d'un logiciel ou d'un système informatique doit être obligatoirement précédée d'une étape d'analyse et de conception qui a pour objectif de définir et de formaliser les étapes nécessaires du développement de l'application afin de rendre cette dernière plus fidèle aux besoins.

La première motivation de ce travail été de fournir un outil qui permet à l'utilisateur de faire ça revue de presse quotidienne de la façon la plus efficace et la plus enrichissante possible tout en considérant ses centres d'intérêts et préférences. 

Le logiciel que nous proposons enchaîne les processus de catégorisation, de résumé, de traduction et de recommandation d'articles de presse. Pour parvenir à réaliser cet ensemble de tâches en deux langues (Anglais et Arabe), nous allons présenter dans cette partie notre conception qui décrit d'une manière claire et précise le fonctionnement de chaque module du système. 


\section{Module de recommandation}
Dans cette partie, nous allons voir la conception détaillée de notre système de recommandation. Ci-dessous, nous présentons les deux approches proposées, la recommandation personnalisée et non personnalisée d'articles de presse  : 
    \subsection{Recommandation personnalisée}
    La recommandation des articles pour les utilisateurs est basée sur le contenu de leurs profils. En effet, le profilage utilisateur débute lorsque l'utilisateur s'authentifie pour la première fois et à chaque fois les informations relatives à ses préférences sont récoltées et traitées.\\
    Cette étape nécessite le profilage de l'utilisateur et le calcul de similarité entre utilisateurs. Dans ce qui suit les détails de chacun.

        \subsubsection{Profilage d'un utilisateur}
        Elle consiste à déterminer les centres d'intérêts d'un utilisateur tout en se basant sur les articles lus par ce dernier. Pour cela, nous avons décidé d'utiliser une méthode de calcul des préférences afin de mieux cibler les utilisateurs et garantir une solution conforme aux caractéristiques de la recommandation pour les articles de presse. 

        Pour le calcul des préférences utilisateurs, nous avons utiliser une méthode de calcul qui permet à la fois de résoudre les problèmes de récence \autoref{} et le démarrage à froid \autoref{}. Cette méthode testée s'avère très efficace par rapport aux méthodes existantes et décrites dans \autoref{}.

        Le calcul de la probabilité de sélection d'une catégorie pour un utilisateur est basé sur ses interactions avec les articles de presse disponible. En effet, dés qu'un est sélectionné, l'information est sauvegardée et utilisée pour la mise à jour du vecteur des catégories préférées \autoref{}.

        L'exemple suivant présente un vecteur de probabilité de sélection pour les catégories préférées d'un utilisateur U :
            \[P(U) = {'sport': 0.7178, 'news': 0.1581, 'sci\_tech': 0.1492}\]            
        Il faut noter que la taille du vecteur de probabilité de sélection des catégories préférées est différentes d'un utilisateur à un autre.

        Ce vecteur se mets à jour, comme déjà cité, après chaque interaction de l'utilisateur U avec l'article A de la catégorie C. Au fur et à mesure, la probabilité de sélection d'une catégorie C\textsubscript{i} augmente si cette dernière est sélectionnée, sinon elle diminue pour donner moins d'importances aux articles qui en font partis!!

        Ci-après les formules dédiées à cet effet :\\
            \[
            P(U, C) =
            \begin{cases}
                (1-{\alpha}) * {P(U, C)} + {\alpha} & \text{si } \text{article A est sélectionne} \\
                (1-{\alpha}) * {P(U, C)} & \text{sinon.}
            \end{cases}
            \]

        Avec initialement :\\
        \[
        \begin{cases}
            P(U, C) = 1 / NbC \forall \text{C} \in \{categorie\textsubscript{1}, categorie\textsubscript{2}, ..., categorie\textsubscript{NbC}\}\\
            NbC : \text{nombre de categories}\\
            \alpha = \text{une constante empirique représentant le biais pour la diminution}
        \end{cases}
        \]
        \begin{algorithm2e}[H]
        \SetAlgoLined
        \SetKwInOut{Input}{input}
        \SetKwInOut{Output}{output}
        \Input{A: Article, U: Utilisateur}
        \textbf{const :} \alpha = 0.1, NbC = nombre de catégories\\
        préférences = U.préférences\\
        catégorie = A.catégorie\\
        \eIf{catégorie \in préférences}{
            préférences[catégorie] = (1-{\alpha}) * {préférences[catégorie]} + {\alpha}\\
            \While{i < taille(préférences)}{
                \If{préférences[i] != catégorie}{
                    préférences[i] = (1-{\alpha}) * {préférences[catégorie]}\\
                }
            } 
        }
        {
            préférences[catégorie] = 1 / NbC
        }
        \caption{Algorithme de profilage d'un utilisateur}
        \end{algorithm2e}
        \subsubsection{Similarité entre utilisateurs}
        Afin de diversifier la recommandation des articles de presse, nous avons mis en place une méthode de calcul de similarité qui permet de recommander des articles par rapport à la similarité entre utilisateurs. 

        Selon \cite{euclidepreuve} qui propose une étude détaillé sur les mesures de similarité pour le filtrage collaboratif, il en est ressorti comme conclusion que la distance euclidienne était la mesure la plus adéquate en terme de précision et temps d'exécution. La formule de calcul de la distance euclidienne est la suivante :

        \begin{itemize}[label={}, leftmargin=0cm]
            \item Soient U\textsubscript{1} et U\textsubscript{2} deux utilisateurs,
            \item P(U\textsubscript{1}) et P(U\textsubscript{2}) les vecteurs de probabilité de sélection des catégories préférées des deux utilisateurs,
            \item NbC\textsubscript{1} et NbC\textsubscript{2} le nombre de catégories préférées de chaque utilisateur,\  
            \item \[Sim({P(U\textsubscript{1})}, {P(U\textsubscript{2})}) = d({P(U\textsubscript{1})}, {P(U\textsubscript{2})}) = {\sqrt {\sum _{i=1, j=1}^{NbC\textsubscript{1},NbC\textsubscript{2}}(P(U\textsubscript{1}, C\textsubscript{i})-P(U\textsubscript{2}, C\textsubscript{j}))^{2}}}\]
        \end{itemize}

        Dans ce qui suit, un exemple de calcul de similarité entre deux utilisateurs :
        \[
        \begin{cases}
            P(U\textsubscript{1}) = {'sport': 0.7581, 'sci\_tech': 0.4492, 'religion': 0.3878, 'algeria': 0.0178,}\\
            P(U\textsubscript{2}) = {'religion': 0.8813,'sport': 0.4421, 'business': 0.3519}\\
        \end{cases}
        \]
        On ignore les probabilités de séléction des catégories non commune entre les deux utilisateurs.
        \[
        \begin{cases}
        d({'sport'}) = P(U\textsubscript{1},'sport')-P(U\textsubscript{2},'sport') = 0.7581 - 0.4421 = 0.32\\
        d({'religion'}) = P(U\textsubscript{1},'religion')-P(U\textsubscript{2},'religion') = 0.3878 - 0.8813 = −0,49 \\
        Sim({P(U\textsubscript{1})}, {P(U\textsubscript{2})}) = {\sqrt {d({'sport'})^{2}+d({'religion'})^{2}}}= {\sqrt{(0.32)^{2} + (-0.49)^{2}}} = 0,59
        \end{cases}
        \]
        \begin{algorithm2e}[H]
        \SetAlgoLined
        \SetKwInOut{Input}{input}
        \SetKwInOut{Output}{output}
        \Input{A: Article, U: utilisateur}
        \textbf{const :} seuil = 0.1\\
        utilisateurs = lire(base de profils)\\
        \While{i < taille(utilisateurs)}{
            \If{utilisateurs[i] != U}{
                similarité = distance\_euclidienne(U.préférences, utilisateurs[i].préférences)\\
                \If{similarité >= seuil}{
                    U.préférences += utilisateurs[i].préférences
                }
            }
        } 
        \caption{Algorithme de calcul de similarité entre utilisateurs}
        \end{algorithm2e}

    \subsection{Recommandation non personnalisée}
    La recommandation non personnalisée vise à recommander des articles pour des utilisateurs qui n'ont pas de comptes (i.e : qui sont non authentifiés), pour cela notre système effectue une recommandation selon le choix de lecture de l'utilisateur, c'est à dire par calcul de similarité entre l'article qui est entrain d'être lu et les nouveaux articles disponible. 

    Un pré-traitement est effectué sur chaque article comprend la suppression des mots vides et l'extraction des racines de mots. Ensuite, le sac à mots de l'article est converti en TF-IDF.  

    Le de calcul de la similarité entre les articles est présenté ci-dessous:

    \begin{itemize}[label={}, leftmargin=0cm]
        \item Soient U un utilisateur, A\textsubscript{1} et A\textsubscript{2} deux articles de presse,
        \item A\textsubscript{1} a été déjà sélectionné et A\textsubscript{2} est un nouvel article,
        \item BoW(A\textsubscript{1}) et BoW(A\textsubscript{2}) les sacs à mots (Bag of Words) de chaque article,\\

        \item BoW(A\textsubscript{1}) = \{\begin{arab}'لواء', 'شفيق', 'مدير', 'مكتب', 'رئيس', 'مخلوع', 'مبارك', 'أراد', 'دائم', 'إيقاع', 'عمر', 'سليمان', 'مشير', 'طنطاوي', 'وصف', 'لواء', 'شفيق', 'عاش', 'قصر', 'رئيس', 'مصري', 'مخلوع', 'وفاة', 'عمر', 'سليمان', 'رئيس', 'مخابرة', 'مصري', 'نائب', 'مبارك', 'خسارة', 'أكبر', 'مصر', 'رجل', 'أفضل', 'رجل', 'شجع', 'صعب', 'تعويض', 'تحدث', 'لواء', 'شفيق', 'تصريح', 'علاقة', 'عمر', 'سليمان', 'رئيس', 'مخلوع', 'مبارك'\end{arab}\},

        \item BoW(A\textsubscript{2}) = \{\begin{arab}'استمر' 'نزاع', 'رئيس', 'وزير', 'نوري', 'مالكي', 'شيعي', 'خصم', 'حكم', 'أنصار', 'قائمة', 'عراقي', 'لواء', 'خلفية', 'اتهام', 'مالكي', 'نائب', 'رئيس', 'طارق', 'هاشمي', 'شجع', 'ضلع', 'عملية', 'إرهابي', 'أمر', 'أدى', 'تجميد', 'نشاط', 'حكومة', 'انسحاب', 'وزير', 'قائمة', 'عراقي', 'تفاقم', 'خلاف', 'نظر', 'مطالبة', 'تيار', 'رجل', 'صدري', 'قائمة', 'عراقي', 'علاقة', 'حل', 'برلمان'\end{arab}\},


        \item TF-IDF(A\textsubscript{1}) = \{0.0766346 , 0.05452615 , 0.4598076 , 0.1090523,  0.076346, 0.0766346, 0.0766346, 0.1090523, 0.16357845, ...\},

        \item TF-IDF(A\textsubscript{2}) = \{0.0261347 , 0.156338 , 0.229038 , 0.0730857,  0.0520013, 0.0816399, 0.0261347, 0.2299038, 0.16357845, ...\},

        \item \[sim\_cos(TF-IDF(A\textsubscript{1}), TF-IDF(A\textsubscript{2})) = \frac {TF-IDF(A\textsubscript{1}) \cdot TF-IDF(A\textsubscript{2})}{||TF-IDF(A\textsubscript{1})|| \cdot ||TF-IDF(A\textsubscript{2})||}\]
    \end{itemize}
    \begin{algorithm2e}[H]
        \SetAlgoLined
        \SetKwInOut{Input}{input}
        \SetKwInOut{Output}{output}
        \Input{A: Article, U: utilisateur}
        \Output{ListeArticlesSimilaires: Article}
        articles = lire(base de articles)\\
        \While{i < taille(articles)}{
            segmentation(articles[i])\\
            suppression\_mots\_vides(articles[i])\\
            racinisation(articles[i])\\
        }
        tf-idf = TF-IDF(articles)\\
        mat\_similarité = TRI(cosinus\_similarité(tf-idf))\\
        ListeArticlesSimilaires = mat\_similarité.articles\\
        \Return ListeArticlesSimilaires[:5]
        \caption{Algorithme de calcul de similarité entre articles}
    \end{algorithm2e}
    % Say something
    % \begin{algorithm2e}[H]
    %     \SetAlgoLined
    %     \SetKwInOut{Input}{input}
    %     \SetKwInOut{Output}{output}
    %     \Input{A: Article, U: utilisateur}
    %     \Output{ListeArticlesSimilaires: Article}
    %     % \eIf{U est authentifié}{
    %     % }
    %     \caption{Algorithme de calcul de similarité entre articles}
    % \end{algorithm2e}